<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Saurav Kumar Roy | Diffusion based poem genrator</title>
<meta name=viewport content="width=device-width,minimum-scale=1"><meta name=generator content="Hugo 0.123.7"><meta name=ROBOTS content="INDEX, FOLLOW"><link href=/dist/app.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.css integrity=sha384-zh0CIslj+VczCZtlzBcjt5ppRcsAmDnRem7ESsYwWwg3m/OaJ2l4x7YBZl9Kxxib crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/katex.min.js integrity=sha384-Rma6DA2IPUwhNxmrB/7S3Tno0YY7sFu9WSYMCuulLhIqYSGZ2gKCJWIqhBWqMQfh crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.21/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script><script>(function(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(e)}),i.parentNode.insertBefore(n,i)})("https://Sauravroy34.github.io/lib/pangu.min.js",function(){pangu.spacingPage()})</script></head><body class="bg-gray-100 text-gray-700 font-sans"><div class="p-6 sm:p-10 md:p-16 flex flex-wrap"><header class="w-full md:w-2/5 xl:w-1/2 md:pr-12 lg:pr-20 xl:pr-24 order-1 md:order-1 max-w-2xl"><div class="z-50 bg-gray-100 bg-opacity-75 bg-opacity-custom lg:min-w-0.7 max-w-xl md:float-right md:text-right leading-loose tracking-tight md:sticky md:top-0 pt-2"><div><h2><a href=https://Sauravroy34.github.io/ title="Saurav Kumar Roy" class="heading font-cursive icon">Saurav Kumar Roy</a></h2></div><h1 class=pt-2>Diffusion based poem genrator</h1><h3 class="text-java-700 font-normal leading-relaxed pt-2">Diffusion based text genrator</h3><div class="flex flex-wrap justify-end pt-2"><div class="md:flex-grow-0 font-light"></div><time class="text-eucalyptus-500 md:text-right md:flex-grow font-light pl-4" datetime=2025-09-17T22:20:03+05:30>2025-9-17</time></div><hr></div></header><main role=main class="w-full md:w-3/5 xl:w-1/2 max-w-3xl order-2 md:order-2 min-h-70vh pt-2 pb-4"><article><section class="mx-auto content"><div class=c-rich-text><h1 id=diffusion-based-poem-generator-using-latent-diffusion>Diffusion-based poem generator using latent diffusion</h1><p>This project implements a diffusion-based text generator to create poems using latent diffusion. Poems were encoded into latent space using the BART encoder-decoder, with its parameters frozen during training to accelerate the process. However, the encoded latent space was length-dependent. To address this, a Perceiver sampler was used to convert the encoded latent space into a fixed 32x64 representation, which was then reshaped into 32x16x4 and passed through the forward diffusion process and later for denoising using the NVIDIA Sana model. The model&rsquo;s parameters were reduced to speed up training. Diffusion models were chosen due to their ability to understand patterns effectively, as discussed in<a href=https://arxiv.org/pdf/2310.02557>GENERALIZATION IN DIFFUSION MODELS ARISES FROM
GEOMETRY-ADAPTIVE HARMONIC REPRESENTATIONS</a></p><h3 id=bart>Bart</h3><p><img src=https://github.com/user-attachments/assets/2dc8a0d7-051d-431c-87b5-67df2c5b96e5 alt=Bart></p><h3 id=perceiver-sampler>Perceiver sampler</h3><h3 id=nvida-sana>Nvida Sana</h3><h2 id=overall-architecture>Overall architecture</h2><h2 id=dataset>Dataset</h2><p>The dataset used was taken from <a href=https://www.kaggle.com/datasets/michaelarman/poemsdataset>Kaggle</a> which contains two folders, both containing subfolders of poems. These poems are categorized by the form (e.g. haiku, sonnet, etc.) or topic (love, nature, joy, peace, etc.).</p><h3 id=step-1-finetuning-language-encoder>Step 1: Finetuning language encoder</h3><p>For encoding and decoding, BART was used with its parameters frozen during training to focus on learning the encoding process (using sequences of 64 tokens). The encoded latent space was then resampled using the Perceiver sampler, which mapped the samples to a 32x64 representation. This was later used to train the diffusion transformer.</p><h3 id=step-2-forward-diffusion-process>Step 2: Forward diffusion process</h3><p>Random noise was then added to the latents</p><h3 id=step-3-encoding-prompts>Step 3: Encoding prompts</h3><p>To encode prompts <a href=https://huggingface.co/HuggingFaceTB/SmolLM2-360M>SmolLm2-360M</a> was used</p><h3 id=step-4-training-the-nvidia-sana-model>Step 4: Training the NVIDIA Sana model</h3><p>Over here, NVIDIA&rsquo;s Sana model was used to predict noise and denoise it. The number of parameters was reduced to ease up training
in diffusion.py</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py data-lang=py><span style=display:flex><span>config <span style=color:#f92672>=</span> SanaTransformer2DModel<span style=color:#f92672>.</span>load_config(<span style=color:#e6db74>&#34;Efficient-Large-Model/Sana_600M_1024px_diffusers&#34;</span>, subfolder<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;transformer&#34;</span>)
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;num_layers&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;num_attention_heads&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;attention_head_dim&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;cross_attention_dim&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>768</span>
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;num_cross_attention_heads&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;cross_attention_head_dim&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>64</span>
</span></span><span style=display:flex><span>config[<span style=color:#e6db74>&#34;caption_channels&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>960</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>transformer <span style=color:#f92672>=</span> SanaTransformer2DModel<span style=color:#f92672>.</span>from_config(config)
</span></span></code></pre></div><h3 id=example>Example</h3><p>prompt - romantic output
Relative to be checked, and asexualerdi nightnightnightnightfalled; I&rsquo;m notingeded, and live-standstandingly, listened to listen to listen listen to everything else whileoberoberrounddoorkoombombombroundingly, while rubbing stubbordozieBee</p><h2 id=references>References</h2><ol><li><p>Pre-training languge encoder and reconstruction networks process -> <a href=https://arxiv.org/abs/2212.09462>Latent Diffusion for Language Generation</a></p></li><li><p>Forward-diffusion and noise predictions -> <a href=https://medium.com/@geronimo7/training-a-latent-diffusion-model-from-scratch-897c7b77ece9>Training a Latent Diffusion Model From Scratch</a></p></li><li><p>NVIDIA&rsquo;S SANA -> <a href=https://arxiv.org/html/2410.10629v2>Sana: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers</a></p></li><li><p>BART -> <a href=https://arxiv.org/abs/1910.13461>BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension</a></p></li><li><p>Perceiver -> <a href=https://arxiv.org/abs/2103.03206>Perceiver: General Perception with Iterative Attention</a></p></li></ol><h2 id=future-plan>Future plan</h2><ol><li>For the future, I will be increasing the token size for the language encoder (currently 64) to 416</li><li>Train the transformer for a larger number of epochs</li><li>Try incorporating <a href=https://arxiv.org/abs/2505.21101>Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance</a> to generate higher quality and diverse samples</li></ol><h2 id=steps-to-train>Steps to train</h2><h3 id=training-the-language-encoder>Training the language encoder</h3><p>run <code>python3 bart_latent_model.py</code></p><h3 id=training-the-diffusion-model>Training the diffusion model</h3><p>run <code>python3 diffusion.py</code></p></div></section></article></main><div class="w-full h-0 flex-none order-3"></div><aside role=contentinfo class="w-full md:w-2/5 xl:w-1/2 md:pr-12 lg:pr-20 xl:pr-24 order-4 md:order-3 md:sticky md:bottom-0 self-end max-w-2xl"><div class="md:float-right md:text-right leading-loose tracking-tight md:mb-2"><div class="md:max-w-xs flex flex-col md:items-end"><ul class="font-serif flex-grow-0 flex justify-between flex-wrap md:flex-col"><li class="px-1 md:px-0"><a href=/posts/ title="Posts page" class="font-medium text-medium-red-violet-600 hover:text-medium-red-violet-400">Posts</a></li><li class="px-1 md:px-0"><a href="https://drive.google.com/file/d/1B9D3aysyp2Lq1V3tZ7MRzXV9Ho7AEUOK/view?usp=sharing" title="CV page">CV</a></li></ul><div class="flex flex-wrap-reverse md:justify-end content-end md:content-start justify-start items-start max-h-16"><a href=https://github.com/Sauravroy34 target=_blank class="github icon pl-1 text-eucalyptus-400 hover:text-java-400" title="github link" rel=noopener aria-label="follow on github——Opens in a new window"><div class="fill-current h-8 w-8"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path fill="none" d="M0 0h24v24H0z"/><path fill-rule="nonzero" d="M5.883 18.653c-.3-.2-.558-.455-.86-.816a50.32 50.32.0 01-.466-.579c-.463-.575-.755-.84-1.057-.949a1 1 0 01.676-1.883c.752.27 1.261.735 1.947 1.588-.094-.117.34.427.433.539.19.227.33.365.44.438.204.137.587.196 1.15.14.023-.382.094-.753.202-1.095C5.38 15.31 3.7 13.396 3.7 9.64c0-1.24.37-2.356 1.058-3.292-.218-.894-.185-1.975.302-3.192a1 1 0 01.63-.582c.081-.024.127-.035.208-.047.803-.123 1.937.17 3.415 1.096A11.731 11.731.0 0112 3.315c.912.0 1.818.104 2.684.308 1.477-.933 2.613-1.226 3.422-1.096.085.013.157.03.218.05a1 1 0 01.616.58c.487 1.216.52 2.297.302 3.19.691.936 1.058 2.045 1.058 3.293.0 3.757-1.674 5.665-4.642 6.392.125.415.19.879.19 1.38a300.492 300.492.0 01-.012 2.716 1 1 0 01-.019 1.958c-1.139.228-1.983-.532-1.983-1.525l.002-.446.005-.705c.005-.708.007-1.338.007-1.998.0-.697-.183-1.152-.425-1.36-.661-.57-.326-1.655.54-1.752 2.967-.333 4.337-1.482 4.337-4.66.0-.955-.312-1.744-.913-2.404a1 1 0 01-.19-1.045c.166-.414.237-.957.096-1.614l-.01.003c-.491.139-1.11.44-1.858.949a1 1 0 01-.833.135A9.626 9.626.0 0012 5.315c-.89.0-1.772.119-2.592.35a1 1 0 01-.83-.134c-.752-.507-1.374-.807-1.868-.947-.144.653-.073 1.194.092 1.607a1 1 0 01-.189 1.045C6.016 7.89 5.7 8.694 5.7 9.64c0 3.172 1.371 4.328 4.322 4.66.865.097 1.201 1.177.544 1.748-.192.168-.429.732-.429 1.364v3.15c0 .986-.835 1.725-1.96 1.528a1 1 0 01-.04-1.962v-.99c-.91.061-1.662-.088-2.254-.485z"/></g></svg></div></a><a href=www.linkedin.com/in/saurav-kumar-roy-0aa286280 target=_blank class="linkedin icon pl-1 text-eucalyptus-400 hover:text-java-400" title="linkedin link" rel=noopener aria-label="follow on linkedin——Opens in a new window"><div class="fill-current h-8 w-8"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path fill="none" d="M0 0h24v24H0z"/><path d="M12 9.55C12.917 8.613 14.111 8 15.5 8a5.5 5.5.0 015.5 5.5V21h-2v-7.5a3.5 3.5.0 00-7 0V21h-2V8.5h2v1.05zM5 6.5a1.5 1.5.0 110-3 1.5 1.5.0 010 3zm-1 2h2V21H4V8.5z"/></g></svg></div></a><a href=https://x.com/Sauravnotfound target=_blank class="twitter icon pl-1 text-eucalyptus-400 hover:text-java-400" title="twitter link" rel=noopener aria-label="follow on twitter——Opens in a new window"><div class="fill-current h-8 w-8"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path fill="none" d="M0 0h24v24H0z"/><path fill-rule="nonzero" d="M15.3 5.55a2.9 2.9.0 00-2.9 2.847l-.028 1.575a.6.6.0 01-.68.583l-1.561-.212c-2.054-.28-4.022-1.226-5.91-2.799-.598 3.31.57 5.603 3.383 7.372l1.747 1.098a.6.6.0 01.034.993L7.793 18.17c.947.059 1.846.017 2.592-.131 4.718-.942 7.855-4.492 7.855-10.348.0-.478-1.012-2.141-2.94-2.141zm-4.9 2.81a4.9 4.9.0 018.385-3.355c.711-.005 1.316.175 2.669-.645-.335 1.64-.5 2.352-1.214 3.331.0 7.642-4.697 11.358-9.463 12.309-3.268.652-8.02-.419-9.382-1.841.694-.054 3.514-.357 5.144-1.55C5.16 15.7-.329 12.47 3.278 3.786c1.693 1.977 3.41 3.323 5.15 4.037 1.158.475 1.442.465 1.973.538z"/></g></svg></div></a></div><div class="text-sm text-gray-500 leading-tight a-gray"><br>Built with Hugo and theme <a href=https://github.com/heyeshuang/hugo-theme-tokiwa>Tokiwa</a>. 452 words in this page.</div></div></div></aside><footer class="w-full md:w-3/5 xl:w-1/2 order-3 max-w-3xl md:order-4 pt-2"><hr class=double-line><div class="flex flex-wrap justify-between pb-2 leading-loose font-serif"><a class=flex-grow-0 href=/posts/molgan/><svg class="fill-current inline-block h-4 w-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24"><path fill="none" d="M0 0h24v24H0z"/><path d="M7.828 11H20v2H7.828l5.364 5.364-1.414 1.414L4 12l7.778-7.778 1.414 1.414z"/></svg>
MolGAN</a></div><div></div><hr><div class=pb-2></div><hr></footer><script src=/dist/app.js></script></div></body></html>