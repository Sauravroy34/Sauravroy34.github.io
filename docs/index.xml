<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Saurav Kumar Roy</title><link>https://Sauravroy34.github.io/</link><description>Recent content on Saurav Kumar Roy</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 19 Oct 2025 23:18:09 +0530</lastBuildDate><atom:link href="https://Sauravroy34.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Legal Ease an AI Powered legal document analyser</title><link>https://Sauravroy34.github.io/posts/legal_ease/</link><pubDate>Sun, 19 Oct 2025 23:18:09 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/legal_ease/</guid><description>&lt;h1 id="legal-ease-your-legal-assistant">Legal Ease your legal assistant&lt;/h1>
&lt;h3 id="motive">Motive&lt;/h3>
&lt;p>Ever felt frustrated while reading through legal documents? Or ever felt overwhelmed by the overly &amp;ldquo;formal&amp;rdquo; and boring vocabulary? Then worry not, here&amp;rsquo;s a project I made, Legal Ease, a legal document summariser It&amp;rsquo;s built with Gemini api, and for the UI Streamlit is used, and the project is hosted on Streamlit Cloud.It supports PDF and image, and also has a chat interface for further queries.&lt;/p>
&lt;h3 id="project-url">Project url&lt;/h3>
&lt;p>&lt;a href="https://legal-docs-ease.streamlit.app/">https://legal-docs-ease.streamlit.app/&lt;/a>&lt;/p>
&lt;h3 id="github">github&lt;/h3>
&lt;p>&lt;a href="https://github.com/Sauravroy34/Legal-Ease">https://github.com/Sauravroy34/Legal-Ease&lt;/a>&lt;/p></description></item><item><title>Diffusion based poem genrator</title><link>https://Sauravroy34.github.io/posts/diffusion-based-poem-genrator/</link><pubDate>Wed, 17 Sep 2025 22:20:03 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/diffusion-based-poem-genrator/</guid><description>&lt;h1 id="diffusion-based-poem-generator-using-latent-diffusion">Diffusion-based poem generator using latent diffusion&lt;/h1>
&lt;p>This project implements a diffusion-based text generator to create poems using latent diffusion. Poems were encoded into latent space using the BART encoder-decoder, with its parameters frozen during training to accelerate the process. However, the encoded latent space was length-dependent. To address this, a Perceiver sampler was used to convert the encoded latent space into a fixed 32x64 representation, which was then reshaped into 32x16x4 and passed through the forward diffusion process and later for denoising using the NVIDIA Sana model. The model&amp;rsquo;s parameters were reduced to speed up training. Diffusion models were chosen due to their ability to understand patterns effectively, as discussed in&lt;a href="https://arxiv.org/pdf/2310.02557">GENERALIZATION IN DIFFUSION MODELS ARISES FROM
GEOMETRY-ADAPTIVE HARMONIC REPRESENTATIONS&lt;/a>&lt;/p>
&lt;h3 id="bart">Bart&lt;/h3>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/2dc8a0d7-051d-431c-87b5-67df2c5b96e5" alt="Bart">&lt;/p>
&lt;h3 id="perceiver-sampler">Perceiver sampler&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;h3 id="nvida-sana">Nvida Sana&lt;/h3>
&lt;!-- raw HTML omitted -->
&lt;h2 id="overall-architecture">Overall architecture&lt;/h2>
&lt;!-- raw HTML omitted -->
&lt;h2 id="dataset">Dataset&lt;/h2>
&lt;p>The dataset used was taken from &lt;a href="https://www.kaggle.com/datasets/michaelarman/poemsdataset">Kaggle&lt;/a> which contains two folders, both containing subfolders of poems. These poems are categorized by the form (e.g. haiku, sonnet, etc.) or topic (love, nature, joy, peace, etc.).&lt;/p>
&lt;h3 id="step-1-finetuning-language-encoder">Step 1: Finetuning language encoder&lt;/h3>
&lt;p>For encoding and decoding, BART was used with its parameters frozen during training to focus on learning the encoding process (using sequences of 64 tokens). The encoded latent space was then resampled using the Perceiver sampler, which mapped the samples to a 32x64 representation. This was later used to train the diffusion transformer.&lt;/p>
&lt;h3 id="step-2-forward-diffusion-process">Step 2: Forward diffusion process&lt;/h3>
&lt;p>Random noise was then added to the latents&lt;/p>
&lt;h3 id="step-3-encoding-prompts">Step 3: Encoding prompts&lt;/h3>
&lt;p>To encode prompts &lt;a href="https://huggingface.co/HuggingFaceTB/SmolLM2-360M">SmolLm2-360M&lt;/a> was used&lt;/p>
&lt;h3 id="step-4-training-the-nvidia-sana-model">Step 4: Training the NVIDIA Sana model&lt;/h3>
&lt;p>Over here, NVIDIA&amp;rsquo;s Sana model was used to predict noise and denoise it. The number of parameters was reduced to ease up training&lt;!-- raw HTML omitted -->
in diffusion.py&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-py" data-lang="py">&lt;span style="display:flex;">&lt;span>config &lt;span style="color:#f92672">=&lt;/span> SanaTransformer2DModel&lt;span style="color:#f92672">.&lt;/span>load_config(&lt;span style="color:#e6db74">&amp;#34;Efficient-Large-Model/Sana_600M_1024px_diffusers&amp;#34;&lt;/span>, subfolder&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#34;transformer&amp;#34;&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;num_layers&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;num_attention_heads&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;attention_head_dim&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">64&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;cross_attention_dim&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">768&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;num_cross_attention_heads&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">12&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;cross_attention_head_dim&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">64&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>config[&lt;span style="color:#e6db74">&amp;#34;caption_channels&amp;#34;&lt;/span>] &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">960&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>transformer &lt;span style="color:#f92672">=&lt;/span> SanaTransformer2DModel&lt;span style="color:#f92672">.&lt;/span>from_config(config)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="example">Example&lt;/h3>
&lt;p>prompt - romantic &lt;!-- raw HTML omitted -->
output
Relative to be checked, and asexualerdi nightnightnightnightfalled; I&amp;rsquo;m notingeded, and live-standstandingly, listened to listen to listen listen to everything else whileoberoberrounddoorkoombombombroundingly, while rubbing stubbordozieBee&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Pre-training languge encoder and reconstruction networks process -&amp;gt; &lt;a href="https://arxiv.org/abs/2212.09462">Latent Diffusion for Language Generation&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Forward-diffusion and noise predictions -&amp;gt; &lt;a href="https://medium.com/@geronimo7/training-a-latent-diffusion-model-from-scratch-897c7b77ece9">Training a Latent Diffusion Model From Scratch&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>NVIDIA&amp;rsquo;S SANA -&amp;gt; &lt;a href="https://arxiv.org/html/2410.10629v2">Sana: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>BART -&amp;gt; &lt;a href="https://arxiv.org/abs/1910.13461">BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Perceiver -&amp;gt; &lt;a href="https://arxiv.org/abs/2103.03206">Perceiver: General Perception with Iterative Attention&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="future-plan">Future plan&lt;/h2>
&lt;ol>
&lt;li>For the future, I will be increasing the token size for the language encoder (currently 64) to 416&lt;/li>
&lt;li>Train the transformer for a larger number of epochs&lt;/li>
&lt;li>Try incorporating &lt;a href="https://arxiv.org/abs/2505.21101">Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance&lt;/a> to generate higher quality and diverse samples&lt;/li>
&lt;/ol>
&lt;h2 id="steps-to-train">Steps to train&lt;/h2>
&lt;h3 id="training-the-language-encoder">Training the language encoder&lt;/h3>
&lt;p>run &lt;code>python3 bart_latent_model.py&lt;/code>&lt;/p>
&lt;h3 id="training-the-diffusion-model">Training the diffusion model&lt;/h3>
&lt;p>run &lt;code>python3 diffusion.py&lt;/code>&lt;/p></description></item><item><title>MolGAN</title><link>https://Sauravroy34.github.io/posts/molgan/</link><pubDate>Thu, 28 Aug 2025 22:18:14 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/molgan/</guid><description>&lt;h3 id="molgan-a-genrative-adversal-network-for-small-molecular-graph">MolGan a Genrative adversal network for small molecular graph&lt;/h3>
&lt;p>Recently i worked on a project where i implemented MolGan from scratch in pytorch Molgan which based on WGAN uses graph data and also it has also has a reinforcement learning objective objective that guides the model to generate molecules with specific desired properties, such as high solubility or synthesizability&lt;/p>
&lt;h3 id="model-architecture">Model architecture&lt;/h3>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/fa30d70a-586f-4111-b09f-e44d9d821d1a" alt="model">&lt;/p>
&lt;p>The MolGAN architecture has three main parts: a generator, a discriminator, and a reward network.&lt;/p>
&lt;p>Generator: This network takes a random noise vector and transforms it into a molecular graph. It uses a Multi-Layer Perceptron (MLP) to simultaneously produce an adjacency matrix (A) for chemical bonds and a feature matrix (X) for atom types. Since these are initially probabilities, the model uses categorical sampling to make them discrete, representing a unique molecule.&lt;/p>
&lt;p>Discriminator: The discriminator&amp;rsquo;s job is to tell the difference between a real molecule from the training data and a fake one created by the generator. It uses a Relational Graph Convolutional Network (R-GCN) to understand the graph structure and predicts whether the input molecule is real or fake.&lt;/p>
&lt;p>Reward Network: This network is the key to the reinforcement learning part. It has the same architecture as the discriminator but is used to assess the quality of the generated molecules based on a specific property, like solubility. It provides a &amp;ldquo;reward&amp;rdquo; signal to the generator, encouraging it to create molecules that score higher on this property.&lt;/p>
&lt;p>The discriminator and reward network have the same architectures and receive graphs as inputs. A Relational-GCN and MLPs are used to produce the singular output&lt;/p>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/08dae9d6-48a9-40ee-a078-bcfeaa4f6984" alt="loss">
MolGAN is based on a type of GAN called a Wasserstein GAN (WGAN), which is known for its stable training. The model uses a custom loss function that combines the WGAN loss with a reinforcement learning objective.&lt;/p>
&lt;h3 id="output">Output&lt;/h3>
&lt;h2 id="pure-rl-lamda--0">Pure Rl (lamda = 0)&lt;/h2>
&lt;p>&lt;img src="https://private-user-images.githubusercontent.com/136881235/483899664-524d059e-aabe-4081-b11d-427593cfa8d3.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTY1Nzc1NTUsIm5iZiI6MTc1NjU3NzI1NSwicGF0aCI6Ii8xMzY4ODEyMzUvNDgzODk5NjY0LTUyNGQwNTllLWFhYmUtNDA4MS1iMTFkLTQyNzU5M2NmYThkMy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODMwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgzMFQxODA3MzVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yNDhhZDA1MTk1ZGY4YmY4MmQ1MmIxY2JhN2JkZWUwZmM2MjY5ODgyYzMwZmY1YjZiN2MwNTYzMTE4OTNiYmM4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.aViw6bA3DzHOdRuD9h196irxm9EqeJR0fyzSIXLJGjI" alt="pure">&lt;/p>
&lt;h2 id="mixture-of-wgan-and-rl-lambda--05">Mixture of WGAN and RL (lambda = 0.5)&lt;/h2>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/455a0340-b58d-456f-8425-e099b4f47052" alt="Mix">&lt;/p>
&lt;h2 id="pure-wgan">Pure WGAN&lt;/h2>
&lt;p>&lt;img src="https://private-user-images.githubusercontent.com/136881235/483899686-bdd69193-3ff0-4005-adb9-7465a9eaa542.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTY1Nzc1NTUsIm5iZiI6MTc1NjU3NzI1NSwicGF0aCI6Ii8xMzY4ODEyMzUvNDgzODk5Njg2LWJkZDY5MTkzLTNmZjAtNDAwNS1hZGI5LTc0NjVhOWVhYTU0Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwODMwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDgzMFQxODA3MzVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lOWIxYmE2MDQ4NGMwOWNjZGQ3NGM0ZDczMjM4OWIzMGFjZDJjNGMwNDViZDliNjFhMmY0ZmI0YjlkMzNmN2RkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.AhXBGVjaECd-WU3fI4sVCZw_VzE41-cNVFgtANdfioM" alt="Wgan">
github: &lt;a href="https://github.com/Sauravroy34/Molgan">https://github.com/Sauravroy34/Molgan&lt;/a>&lt;/p></description></item><item><title>Setting Up HEASOFT</title><link>https://Sauravroy34.github.io/posts/setting-up-heasoft/</link><pubDate>Sat, 05 Apr 2025 18:37:50 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/setting-up-heasoft/</guid><description>&lt;h3 id="setting-up-heasoft-a-frustrating-but-rewarding-experience">Setting Up HEASOFT: A Frustrating but Rewarding Experience&lt;/h3>
&lt;p>First of all, I had no idea that setting up HEASOFT would be &lt;em>so&lt;/em> painful. The official documentation didnâ€™t help much, and I needed HEASOFT for my GSoC project with Stingray, where itâ€™s used for Level 1 data processing.&lt;/p>
&lt;h3 id="what-is-heasoft">What is HEASOFT?&lt;/h3>
&lt;p>HEASoft (High Energy Astrophysics Software) is a unified package that includes:&lt;/p>
&lt;ul>
&lt;li>&lt;strong>FTOOLS&lt;/strong>: Tools to manipulate FITS files, both general-purpose and mission-specific.&lt;/li>
&lt;li>&lt;strong>XANADU&lt;/strong>: A set of high-level, multi-mission tasks for analyzing X-ray spectral, timing, and imaging data.&lt;/li>
&lt;/ul>
&lt;p>and lot more !!!
It bundles everything you need to work with X-ray astronomical data. You can download either the source code or precompiled executables depending on your system. It even has a web-based interface called &lt;a href="https://heasarc.gsfc.nasa.gov/docs/sciserver/">sciserver&lt;/a>!.&lt;/p>
&lt;h3 id="how-i-finally-got-heasoft-to-work">How I Finally Got HEASOFT to Work&lt;/h3>
&lt;p>The official documentation didnâ€™t really help me much, so I had to hunt around online. Thankfully, I found an amazing YouTube channel: &lt;a href="https://www.youtube.com/@nspace-cowboy">Nick Space Cowboy&lt;/a>! He has a complete, step-by-step guide on installing HEASOFT, and following it made the process &lt;em>so&lt;/em> much easier.&lt;/p>
&lt;p>It took about an hour to fully install everything, and to my surprise, he also had tutorials on analyzing NICER data, which is super helpful for my project.&lt;/p>
&lt;p>So far, Iâ€™ve managed to:&lt;/p>
&lt;ul>
&lt;li>Set up HEASOFT successfully&lt;/li>
&lt;li>Configure the NICER CALDB (Calibration Database)&lt;/li>
&lt;li>Add geomagnetic files required for preprocessing&lt;/li>
&lt;/ul>
&lt;p>If you&amp;rsquo;re struggling like I was, I &lt;em>highly&lt;/em> recommend checking out Nickâ€™s channel. It might save you hours of frustration.&lt;/p></description></item><item><title>GSoC Proposal</title><link>https://Sauravroy34.github.io/posts/gsoc-proposal/</link><pubDate>Sat, 05 Apr 2025 12:40:00 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/gsoc-proposal/</guid><description>&lt;p>It&amp;rsquo;s been around 8 months since I discovered the Stingray project. My first pull request to the Stingray software involved implementing &lt;a href="https://github.com/StingraySoftware/stingray/pull/847">pre-commit hooks&lt;/a>, which was merged on September 30, 2024. Since then, Iâ€™ve found this package fascinating and have contributed a few more PRs.&lt;/p>
&lt;p>Before this, I didnâ€™t know about Stingray or even the role of Python in astronomy. To be honest, learning how the package works was overwhelming at first, but the journey has been incredibly rewarding. Here&amp;rsquo;s what Iâ€™ve learned so far:&lt;/p>
&lt;ul>
&lt;li>The physics of black holes and X-ray binaries&lt;/li>
&lt;li>How light curves and power spectra are used in analysis&lt;/li>
&lt;li>Various statistical and signal processing methods like correlation and Fourier transforms&lt;/li>
&lt;li>Different states of black holes and the radio jets they emit during transitions from soft to hard states (and vice versa)&lt;/li>
&lt;li>Tools used in astronomy like HEASOFT&lt;/li>
&lt;li>How CCDs in telescopes work, and much more&lt;/li>
&lt;/ul>
&lt;p>Iâ€™m proud that I was able to learn all of this while still pursuing my B.Tech!&lt;/p>
&lt;h3 id="gsoc-project">GSoC Project&lt;/h3>
&lt;p>The project I&amp;rsquo;m interested in is &lt;a href="https://openastronomy.org/gsoc/gsoc2025/#/projects?project=interactive_database_for_x-ray_observations">Interactive Database for X-ray Binary Observations&lt;/a>, a 350-hour GSoC project. The goal is to build a catalog of black hole binaries where users can track their evolution using a &lt;a href="https://www.researchgate.net/figure/The-hardness-intensity-diagram-showing-the-added-information-gained-when-including-the_fig1_230595369#:~:text=The%20hardness%2Dintensity%20diagram%20showing%20the%20added%20information%20gained%20when,and%20darker%20to%20lower%20flux.">Hardness-Intensity Diagram (HID)&lt;/a>â€”a plot showing photon intensity and the ratio of counts across specific energy bands (e.g., [2â€“4 keV]/[4â€“12 keV]).&lt;/p>
&lt;p>The database would include Fourier and timing products like light curves, power spectra, and energy spectra for each observation. Currently, most analyses focus on individual observations, which is useful for estimating spin and mass, but this project aims to provide a complete overview of a black hole&amp;rsquo;s evolution over time.&lt;/p>
&lt;h3 id="my-proposal">My Proposal&lt;/h3>
&lt;p>After two months of trial and errorâ€”learning, exploring, and refiningâ€”the proposal is finally ready! This is my first time writing such a detailed technical document. I plan to submit it soon, as the deadline is April 8, 2025.&lt;/p>
&lt;p>Fingers crossed! Let&amp;rsquo;s hope for the best! ðŸ™Œ&lt;/p></description></item><item><title>JWST Light Curve and Planet Spectra</title><link>https://Sauravroy34.github.io/posts/jwst-light-curve-and-planet-spectra/</link><pubDate>Sat, 05 Apr 2025 00:32:11 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/jwst-light-curve-and-planet-spectra/</guid><description>&lt;h3 id="wasp-39b-light-curve-and-planet-spectra">WASP-39b Light Curve and Planet Spectra&lt;/h3>
&lt;p>Recently, I worked on a cool project where I plotted the light curve of the star &lt;strong>WASP-39&lt;/strong>, during which its exoplanet â€” the hot Jupiter &lt;strong>WASP-39b&lt;/strong> â€” was also observed. According to &lt;a href="https://exoplanetarchive.ipac.caltech.edu/overview/WASP-39#planet_WASP-39-b_collapsible">NASA&amp;rsquo;s exoplanet archive&lt;/a>, WASP-39b has about &lt;strong>0.28 times the mass of Jupiter&lt;/strong> and a &lt;strong>radius 1.27 times that of Jupiter&lt;/strong> (~91,000 km).&lt;/p>
&lt;p>It&amp;rsquo;s a hot gas giant with a scorching temperature of around &lt;strong>900â€¯Â°C&lt;/strong>. The planet orbits very close to its host star (about &lt;strong>7 million km away&lt;/strong>) and completes one orbit in just &lt;strong>4 days&lt;/strong>.&lt;/p>
&lt;p>WASP-39b was the &lt;strong>first exoplanet discovered to contain carbon dioxide in its atmosphere&lt;/strong>, and sulfur dioxide was also detected. It lies in the &lt;strong>Virgo&lt;/strong> constellation and is about &lt;strong>700 light-years away&lt;/strong> from Earth. As part of the NameExoWorlds campaign for the IAUâ€™s 100th anniversary, the planet was officially named &lt;strong>Bocaprins&lt;/strong>, after &lt;em>Boca Prins&lt;/em> beach in Arubaâ€™s Arikok National Park. The star it orbits is &lt;strong>WASP-39&lt;/strong>.&lt;/p>
&lt;hr>
&lt;h3 id="what-is-a-light-curve">What Is a Light Curve?&lt;/h3>
&lt;p>In simple terms, a &lt;strong>light curve&lt;/strong> is a plot of incoming light (photon counts or flux) versus time. It shows how the brightness of a star changes over a period (called exposure time). Telescopes observe these light curves by continuously watching a star.&lt;/p>
&lt;p>One fascinating use of light curves is to detect exoplanets. When a planet passes in front of its star (a transit), it causes a small dip in the light curve â€” and thatâ€™s how astronomers discover new worlds!&lt;br>
Learn more about this method &lt;a href="https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets#Transit_photometry">here&lt;/a>.&lt;/p>
&lt;hr>
&lt;h3 id="what-are-planet-spectra">What Are Planet Spectra?&lt;/h3>
&lt;p>When telescopes use &lt;a href="https://noirlab.edu/public/blog/50-years-ccds/">CCD detectors&lt;/a>, they can measure not just when photons arrive, but also their &lt;strong>energy&lt;/strong> and &lt;strong>count&lt;/strong>. Using this information, we can create a &lt;strong>spectrum&lt;/strong> of the planet â€” which is basically a plot of photon flux (or counts) vs &lt;strong>wavelength&lt;/strong>.&lt;/p>
&lt;p>This tells us what elements or molecules are present in the planetâ€™s atmosphere. Want to go deeper? Check out &lt;a href="https://oxfordre.com/planetaryscience/display/10.1093/acrefore/9780190647926.001.0001/acrefore-9780190647926-e-134">this article on planetary spectroscopy&lt;/a>.&lt;/p>
&lt;hr>
&lt;h3 id="datasets-and-project-implementation">Datasets and Project Implementation&lt;/h3>
&lt;p>The dataset for this project came from the &lt;strong>James Webb Space Telescope (JWST)&lt;/strong> using its &lt;strong>NIRSpec instrument&lt;/strong>, specifically in &lt;strong>Bright Object Time-Series (BOTS)&lt;/strong> mode. For more details, visit the &lt;a href="https://jwst-docs.stsci.edu/jwst-near-infrared-spectrograph/nirspec-observing-modes/nirspec-bright-object-time-series-spectroscopy#gsc.tab=0">official JWST documentation&lt;/a>.&lt;/p>
&lt;p>The data was downloaded from the &lt;a href="https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html">MAST Portal&lt;/a> and came in &lt;strong>FITS format&lt;/strong>, which is the standard for astronomy data.&lt;/p>
&lt;p>The project was done entirely in a &lt;strong>Jupyter Notebook&lt;/strong>, and here are some of the interesting visualizations I generated:&lt;/p>
&lt;h4 id="light-curve-and-poisson-regression-fit">Light Curve and Poisson Regression Fit&lt;/h4>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/98ce41e7-a80d-44f8-8ad1-bdd080a7919d" alt="Light Curve Plot">&lt;/p>
&lt;h2 id="transmission-spectroscopy">Transmission Spectroscopy&lt;/h2>
&lt;p>When a planet transits, some starlight passes through its atmosphere. Different wavelengths of light are absorbed by atmospheric molecules, causing variations in the transit depth. Plotting these variations against wavelength produces a transmission spectrum, which reveals details about the atmosphereâ€™s composition. For a clear explanation, watch this &lt;a href="https://www.youtube.com/watch?v=ZnLg4YFMfDQ&amp;amp;ab_channel=MartianColonist">video&lt;/a>.&lt;/p>
&lt;h3 id="transmission-spectrum-of-wasp-39b">Transmission Spectrum of WASP-39b&lt;/h3>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/66baeb9c-f64f-4c27-a1e9-f8a0d4cc22d4" alt="Transmission Spectrum">&lt;/p>
&lt;p>The spectrum above shows how WASP-39bâ€™s atmosphere affects light at different wavelengths.&lt;/p>
&lt;h2 id="detecting-atmospheric-composition">Detecting Atmospheric Composition&lt;/h2>
&lt;p>To determine the atmospheric composition, we use atmospheric retrieval. This involves comparing observed data to model spectra generated with known compositions. The model that best fits the data indicates the likely atmospheric makeup. For more insights, refer to this &lt;a href="https://www.youtube.com/watch?v=ZnLg4YFMfDQ&amp;amp;ab_channel=MartianColonist">video&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/5efc277a-e584-465d-a986-0e71490eb463" alt="Model Fit">&lt;/p>
&lt;h2 id="composition-of-wasp-39bs-atmosphere">Composition of WASP-39bâ€™s Atmosphere&lt;/h2>
&lt;p>As a hot Jupiter, WASP-39b is expected to contain gases like methane and carbon dioxide. Analysis confirms the presence of water, sulfur dioxide, methane, and carbon dioxide. A distinct bump in the transmission spectrum between 4â€“5 Âµm confirms carbon dioxide.&lt;/p>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/e8355d1c-d8f0-4439-9119-03fb3b6278e4" alt="Molecular Contributions">&lt;/p>
&lt;h2 id="pressure-temperature-profile">Pressure-Temperature Profile&lt;/h2>
&lt;p>The retrieval process assumes a &lt;a href="https://www.aanda.org/articles/aa/pdf/2010/12/aa13396-09.pdf">Guillot pressure-temperature profile&lt;/a> to model the atmosphereâ€™s temperature structure.&lt;/p>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/dcdc5ea5-c144-445e-8c7c-2e1c59e9e020" alt="Pressure-Temperature Profile">&lt;/p>
&lt;h2 id="molecular-abundance">Molecular Abundance&lt;/h2>
&lt;p>The abundance of molecules like water, methane, carbon dioxide, and sulfur dioxide varies with atmospheric pressure, as shown below.&lt;/p>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/c709a606-6ba8-4fbd-9932-38365baae326" alt="Pressure vs. Abundance">&lt;/p>
&lt;p>The transmission spectrum highlights specific absorption features for each molecule.&lt;/p>
&lt;p>&lt;img src="https://github.com/user-attachments/assets/af1bfc59-19cb-4ed1-849d-48ad3108ddeb" alt="Chemical Lines">&lt;/p>
&lt;p>REEFRENCES:&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=ZnLg4YFMfDQ">https://www.youtube.com/watch?v=ZnLg4YFMfDQ&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://petitradtrans.readthedocs.io/en/latest/">https://petitradtrans.readthedocs.io/en/latest/&lt;/a>&lt;/li>
&lt;/ol>
&lt;hr>
&lt;h3 id="project-repository">Project Repository&lt;/h3>
&lt;p>You can check out the complete code and analysis on GitHub:&lt;br>
ðŸ‘‰ &lt;a href="https://github.com/Sauravroy34/JWST-light-curve-and-spectral-analysis">JWST Light Curve and Planet Spectra&lt;/a>&lt;/p></description></item><item><title>My Open Source Journey</title><link>https://Sauravroy34.github.io/posts/my-open-source-journey/</link><pubDate>Fri, 04 Apr 2025 16:00:58 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/my-open-source-journey/</guid><description>&lt;h2 id="my-open-source-journey">My Open Source Journey&lt;/h2>
&lt;p>It&amp;rsquo;s been around &lt;strong>8 months&lt;/strong> since I started contributing to &lt;strong>open source&lt;/strong>, beginning with &lt;a href="https://openastronomy.org/">OpenAstronomy&lt;/a>!&lt;/p>
&lt;p>OpenAstronomy is an umbrella organization, and within it, I am an active contributor to:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/sunpy/sunpy">SunPy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/StingraySoftware/stingray">Stingray Software&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="an-incredible-journey-so-far">An Incredible Journey So Far&lt;/h3>
&lt;p>This journey has been &lt;strong>amazing&lt;/strong>! I&amp;rsquo;ve had the opportunity to interact with incredible peopleâ€”some are &lt;strong>researchers&lt;/strong>, some work at &lt;strong>NASA&lt;/strong> and &lt;strong>ESA&lt;/strong>, and others are &lt;strong>professors at top universities&lt;/strong>.&lt;/p>
&lt;p>Through open source, I&amp;rsquo;ve learned &lt;strong>a lot&lt;/strong> about:&lt;/p>
&lt;ul>
&lt;li>Computational Astronomy&lt;/li>
&lt;li>Coding Standards&lt;/li>
&lt;li>Unit Testing with &lt;code>pytest&lt;/code>&lt;/li>
&lt;li>Documentation with &lt;code>Sphinx&lt;/code>&lt;/li>
&lt;li>Pre-commit Hooks&lt;/li>
&lt;li>learned how to work with File formats like &lt;code>FITS&lt;/code> and &lt;code>ASDF&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>By the way i got into open source around september 2024 and journey has been amazing so far!!&lt;/p></description></item><item><title>My First Post</title><link>https://Sauravroy34.github.io/posts/my-first-post/</link><pubDate>Fri, 04 Apr 2025 15:57:50 +0530</pubDate><guid>https://Sauravroy34.github.io/posts/my-first-post/</guid><description>&lt;p>Hi I am Saurav Kumar Roy a undergrad student from Amrita Viswa Vidyapeetham Amritapuri in India and This is my new blogging site. I will be posting my journey and experiences here. Enjoy!&amp;quot;&lt;/p></description></item></channel></rss>